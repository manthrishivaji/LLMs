# LLMs

1. It is a code for text summarization, implemented from scratch on base transformer where normal positional encoding is modified with Rotary positional encoding.

Note : Used less data , to get better results try to train with more data.
